{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRfRcVC/VQshQWbM6x4AjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YukiAoki-GU/-Mathematical_analysis_by_Python/blob/main/AI%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%AA%E3%82%A2%E3%83%AB%E3%83%AF%E3%83%BC%E3%83%AB%E3%83%89%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E8%A9%95%E4%BE%A12025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIを使ったリアルワールドデータ(RWD)の評価\n",
        "\n"
      ],
      "metadata": {
        "id": "_zncPLLtGnm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RWDとは？**"
      ],
      "metadata": {
        "id": "RjOgY2Uzi-Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#こちらの動画を見てください。\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "<a href=\"https://www.youtube.com/watch?v=UtH22-nplVU\" target=\"_blank\">\n",
        "▶ YouTubeで動画を見る\n",
        "</a>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "l4FYKWK17IU_",
        "outputId": "1dcc21a5-9ba3-4a49-e602-ef830e0e5d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<a href=\"https://www.youtube.com/watch?v=UtH22-nplVU\" target=\"_blank\">\n",
              "▶ YouTubeで動画を見る\n",
              "</a>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RWD には明確な定義はありませんが、大規模な患者レジストリーや保険データベース、電子カルテデータを含むデータベースなど、日々の臨床から収集した患者情報のデータベースの総称の意味合いで広く使われています。\n",
        "\n",
        "\n",
        "\n",
        "公的機関が運営する代表的なリアルワールドデータは以下：\n",
        "* NDB(ナショナルデータベース)：厚生労働省が提供する、公益目的のリアルワールドデータ。データの提供は行政機関や大学、研究をする独立行政法人、国直轄の公益法人や国の行政機関に限られる。\n",
        "* MID-NET(医療情報データベース、ミッドネット): 全国23の大病院から電子カルテなどを集めた、製造販売後の調査、もしくは公益性の高い研究のために用いられるリアルワールドデータ。PMDAが管理・運営している。提供は、厚生労働省が開発要請をした医薬品についての実態調査、国や自治体、独立行政法人などの公的研究費による研究に限られる。"
      ],
      "metadata": {
        "id": "QADdeCFrRJC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## なぜRWDなのか？\n",
        "日常診療の中で集められたデータであり、例えば\n",
        "- 電子カルテ(EHR)\n",
        "- DPCデータ\n",
        "- レセプト\n",
        "- 患者登録・レジストリ\n",
        "- ウエアブル\n",
        "- バイオマーカー\n",
        "- 検査データ\n",
        "\n",
        "臨床研究のスタンダードはランダム化比較試験(Randomized Controlled Trial: RCT)ですが、臨床研究のゴールド・スタンダードはランダム化比較試験 （Randomized Controlled Trial: 以下 RCT）ですが、特に医療の世界では RCT が倫理的または費用的な面で実施困難であることが多く、また厳しく統制された RCT で得られた知見を実際の臨床に応用できるか保証されないという問題があるため（外的妥当性が保証されない）、近年 RWD を用いた分析の可能性に注目が集まっています。\n",
        "\n",
        "1. 臨床試験の限界\n",
        "従来の臨床試験（ランダム化比較試験、RCT）は、厳密な環境下で行われるため、患者の選定基準が非常に厳格です。これにより、現実の医療現場での患者層（高齢者、併存疾患を持つ患者など）を十分に反映できない場合があります。RWDは、日常の診療で得られる実際のデータを基にしているため、より多様な患者層に基づく実際の医療効果や安全性を評価できます。\n",
        "\n",
        "2. 医薬品の効果・安全性の長期的評価\n",
        "新薬が市場に出た後、臨床試験では確認できなかった長期的な安全性や副作用が現れることがあります。RWDは、医薬品が市場に出た後のリアルタイムでのデータを集め、長期間にわたる効果や副作用の監視に役立ちます。\n",
        "\n",
        "3. 患者中心の医療へのシフト\n",
        "医療は、個別化医療（Precision Medicine）や患者中心の医療に向かっています。RWDは、患者の日常生活や実際の医療現場での経験を反映するデータであり、個々の患者のニーズや治療効果をよりよく理解するための情報源となります。\n",
        "\n",
        "4. コスト削減と効率化\n",
        "従来の臨床試験は非常にコストが高く、時間もかかります。一方、電子カルテ（EHR）、保険データ、ウェアラブルデバイスなどから得られるRWDは、比較的低コストで迅速にデータを収集できるため、医薬品開発や政策決定において重要な役割を果たします。\n",
        "\n",
        "5. 政策と規制の変化\n",
        "RWDが大切になった背景として、医療品に関する法律の改正があります。2018年4月に施行された「医薬品の製造販売後の調査及び試験の実施の基準に関する省令（GPSP省令）」の[改正](https://www.pmda.go.jp/files/000220766.pdf)により、製造販売後の安全性監視活動にリアルワールドデータ（RWD）を活用することが認められました。薬事承認においても、条件付き早期承認制度下での調査でRWDの活用が認められ、さらにはPMDA(独立行政法人医療品医療機器総合機構)のレジストリ・データベースに関する相談窓口の整備されてきました。\n",
        "\n",
        "6. デジタルヘルス技術の進化\n",
        "ウェアラブルデバイス、スマートフォン、IoTなどのデジタル技術が普及し、個々の患者の日常生活での健康状態や行動をリアルタイムでモニタリングできるようになりました。これにより、RWDの質と量が飛躍的に向上し、より精密な分析が可能になっています。\n",
        "\n",
        "このように、リアルワールドデータは従来の臨床試験の補完として、あるいはそれに代わる方法として、医療・ヘルスケアの意思決定においてますます重要な役割を担っています。"
      ],
      "metadata": {
        "id": "X4VDPKGDQ9S-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **AIを使ったRWDの評価**\n"
      ],
      "metadata": {
        "id": "5prHfRzPROPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#こちらの動画を見てください。\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "<a href=\"https://www.youtube.com/watch?v=gugq9ydf8b8\" target=\"_blank\">\n",
        "▶ YouTubeで動画を見る\n",
        "</a>\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "srCqiRHf8YzM",
        "outputId": "24dff962-eee5-4394-b913-74598e44577f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<a href=\"https://www.youtube.com/watch?v=gugq9ydf8b8\" target=\"_blank\">\n",
              "▶ YouTubeで動画を見る\n",
              "</a>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習による予測モデルを実際の医療現場で診断補助として運用するのであれば、「AIの予測はどの程度正しいのか？」を説明できることが重要。\\\n",
        "「機械学習」はコンピュータに物事を学習させることを総称した言葉であり、機械学習の具体的な手法(アルゴリズム)は以下のように多岐にわたります。\n",
        "\n",
        "*   二値分類：\\\n",
        "データを2つのクラスに分類 → 陰性 or 陽性\n",
        "*   回帰による二値分類：\\\n",
        "データの分布をグラフで表したとき、直線を使ってデータを二分(線型回帰)\n",
        "*   多項式回帰による二値分類：\\\n",
        "多項式を使った曲線を使ってデータを二分\n",
        "*   ロジスティック回帰による二値分類：\\\n",
        "回帰の手法では分類困難な場合。例えば、メールのスパムメールと通常メールの二分。このような場合は、「スパムである可能性は80%」のように、確率によるロジスティック回帰で分類\n",
        "*   ニューラルネットワーク：\\\n",
        "動物の神経細胞を模した「人工ニューロン」を複数繋ぎ合わせることで分類する方法。ニューロンの連結数を増やし、人間の脳に近い学習を行わせる手法のことを「**深層学習(ディープラーニング)**」と呼ぶ。"
      ],
      "metadata": {
        "id": "DMjd2XMwnV3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **混同行列、ROC曲線、AUC**"
      ],
      "metadata": {
        "id": "4-DeQuyhiT6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#こちらの動画を見てください。\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "<a href=\"https://www.youtube.com/watch?v=opBZQOa8EZA\" target=\"_blank\">\n",
        "▶ YouTubeで動画を見る\n",
        "</a>\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eMStDzdI8lhz",
        "outputId": "5e878ec5-bd77-4c93-aa1f-920cbbf7ef10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<a href=\"https://www.youtube.com/watch?v=opBZQOa8EZA\" target=\"_blank\">\n",
              "▶ YouTubeで動画を見る\n",
              "</a>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "予想の正しさを定量的に評価するにはどうすれば良いか？\\\n",
        "データを2つのクラス(陰性と陽性)に二値分類するが、\n",
        "* 陰性と分類し本当に陰性であったもの (True Negative)\n",
        "* 陽性と分類し本当に陽性であったもの (True Positive)\n",
        "\n",
        "は、正しい分類である。一方、\n",
        "* 陰性と分類し本当は陽性であったもの (False Positive)\n",
        "* 陽性と分類し本当は陰性であったもの (False Negative)\n",
        "\n",
        "は、誤った分類である。これら4成分を行列としたものを**混同行列**(Confusion Matrix)と言う。\n",
        "\n",
        "$$\n",
        "        \\left[\\begin{array}{c|cc}\n",
        "            TP & FP\\\\\n",
        "            \\hline\n",
        "            FN & TN\\\\\n",
        "        \\end{array}\\right] \\quad\n",
        "$$\n",
        "\n",
        "横軸をFPR(False Positive Rate)、縦軸をTPR(True Positive Rate)としたグラフを**ROC曲線**(Receiver Operating Characteristic曲線)という。\\\n",
        "ROC曲線の下側の面積比が**AUC**(Area Under the ROC Curve)である。\\\n",
        "AUCは0から1の値を取り、1に近いほど分類が正しいことを示す。"
      ],
      "metadata": {
        "id": "Uk2w44b8TafF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **ViTとCNNで画像の二値分類**\n",
        "レントゲン画像を男女に分類しよう。"
      ],
      "metadata": {
        "id": "1Yr-MOs62hWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#こちらの動画を見てください。\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "<a href=\"https://www.youtube.com/watch?v=3JxREAM9YL0\" target=\"_blank\">\n",
        "▶ YouTubeで動画を見る\n",
        "</a>\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dPZsy_nn8zca",
        "outputId": "422c7617-556a-496a-df84-8a26c7038642"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<a href=\"https://www.youtube.com/watch?v=3JxREAM9YL0\" target=\"_blank\">\n",
              "▶ YouTubeで動画を見る\n",
              "</a>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm #モデルのインストール\n",
        "# 必要なライブラリをインポート\n",
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import v2\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "import timm\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XuLw0f983UJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n4rX75Ou2h5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GULMSの「画像データ」から[x-ray.zip](https://mdl.media.gunma-u.ac.jp/course/section.php?id=33666)をダウンロードし、Google Drive/My Drive/に置いてください。"
      ],
      "metadata": {
        "id": "q7-VXtaF3Khi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Zipファイルの解凍\n",
        "file_name = '/content/drive/MyDrive/x-ray.zip'\n",
        "with ZipFile(file_name) as zip:\n",
        "    zip.extractall()"
      ],
      "metadata": {
        "id": "ZDsz83Nf3OXg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`/content/x-ray`のディレクトリができていることを確認してください。"
      ],
      "metadata": {
        "id": "Ea6v5zVI3R0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込みを確認\n",
        "files = glob.glob('/content/x-ray/*/*/*.png')\n",
        "random_idx = np.random.randint(1, len(files), size=9)\n",
        "fig, axes = plt.subplots(3, 3, figsize=(8, 6))\n",
        "\n",
        "for idx, ax in enumerate(axes.ravel()):\n",
        "    img = Image.open(files[idx])\n",
        "    ax.imshow(img)"
      ],
      "metadata": {
        "id": "mVcd9Nkq3e-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "train_dataset_dir = Path('/content/x-ray/train') #訓練データ\n",
        "val_dataset_dir = Path('/content/x-ray/validation') #検証データ(訓練データでは良い精度で予想できるが、それ以外のデータでは、予測が当てにならない→過学習)\n",
        "test_dataset_dir = Path('/content/x-ray/test') #テストデータ"
      ],
      "metadata": {
        "id": "Nedmn76Y3cMH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformを使って、データセットの画像の前処理を行います。\n",
        "#画像のサイズを224×224にリサイズ\n",
        "#左右反転によるData Augmentation\n",
        "#Tensor型へデータ変更\n",
        "#正規化\n",
        "\n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# データセット（画像とラベルのセット）を作成\n",
        "train_data = datasets.ImageFolder(train_dataset_dir,train_transforms)\n",
        "valid_data = datasets.ImageFolder(val_dataset_dir, val_transforms)\n",
        "test_data = datasets.ImageFolder(test_dataset_dir, test_transforms)\n",
        "\n",
        "# データをバッチに分ける。今回は、batch_sizeを16\n",
        "train_loader = DataLoader(dataset = train_data, batch_size=16, shuffle=True )\n",
        "valid_loader = DataLoader(dataset = valid_data, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(dataset = test_data, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "rvTa034f6ltE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "「編集→ノートブックの設定→ハードウェアアクセラレータ→GPU」でGPUの処理に変更してください。"
      ],
      "metadata": {
        "id": "GOlxtd5J3v61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ViTで画像分類"
      ],
      "metadata": {
        "id": "0WhPE6Qu608g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modelのリストを表示\n",
        "model_names = timm.list_models(pretrained=True)\n",
        "pprint(model_names)"
      ],
      "metadata": {
        "id": "WpsHF-j85kOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#今回は‘vit_base_patch16_224_in21k’を使用\n",
        "model = timm.create_model('vit_base_patch16_224_in21k', pretrained=True, num_classes=2)\n",
        "#model = timm.create_model('tf_efficientnetv2_s_in21ft1k', pretrained=True, num_classes=2)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "iSw25v8353A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習条件\n",
        "epochs = 100\n",
        "lr = 0.001\n",
        "\n",
        "#損失関数、活性化関数の設定\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# 学習ループの設定、実行\n",
        "best_loss = None\n",
        "\n",
        "# Accuracy計算用の関数\n",
        "def calculate_accuracy(output, target):\n",
        "    output = (torch.sigmoid(output) >= 0.5)\n",
        "    target = (target == 1.0)\n",
        "    accuracy = torch.true_divide((target == output).sum(dim=0), output.size(0)).item()\n",
        "    return accuracy\n",
        "\n",
        "train_acc_list = []\n",
        "val_acc_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "\n",
        "    for data, label in tqdm(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == label).float().mean()\n",
        "        epoch_accuracy += acc / len(train_loader)\n",
        "        epoch_loss += loss / len(train_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        epoch_val_accuracy = 0\n",
        "        epoch_val_loss = 0\n",
        "        for data, label in valid_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            val_output = model(data)\n",
        "            val_loss = criterion(val_output, label)\n",
        "\n",
        "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
        "            epoch_val_accuracy += acc / len(valid_loader)\n",
        "            epoch_val_loss += val_loss / len(valid_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    train_acc_list.append(epoch_accuracy)\n",
        "    val_acc_list.append(epoch_val_accuracy)\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    val_loss_list.append(epoch_val_loss)\n",
        "\n",
        "    if (best_loss is None) or (best_loss > val_loss):\n",
        "        best_loss = val_loss\n",
        "        model_path = '/content/drive/MyDrive/bestViTmodel.pth' #重みファイル名\n",
        "        #model_path = '/content/drive/MyDrive/bestmodel_efficientnet.pth'\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "HuSkQBeO3x4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータによる検証\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.load_state_dict(torch.load(\"/content/drive/MyDrive/bestViTmodel.pth\")) #重みファイル名\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    probas = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            probas.extend(outputs[:, 1].cpu().numpy())  # 二番目のクラス（陽性クラス）の確率\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    # 指標の計算\n",
        "    confusion = confusion_matrix(actuals, predictions)\n",
        "    accuracy = accuracy_score(actuals, predictions)\n",
        "    recall = recall_score(actuals, predictions)  # 感度\n",
        "    specificity = recall_score(actuals, predictions, pos_label=0)\n",
        "    precision = precision_score(actuals, predictions)  # PPV\n",
        "    npv = precision_score(actuals, predictions, pos_label=0)  # NPV\n",
        "    f1 = f1_score(actuals, predictions)\n",
        "    auc = roc_auc_score(actuals, probas)\n",
        "\n",
        "\n",
        "    #print(\"混同行列:\\n\", confusion)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"感度: {recall:.4f}\")\n",
        "    print(f\"特異度: {specificity:.4f}\")\n",
        "    print(f\"PPV: {precision:.4f}\")\n",
        "    print(f\"NPV: {npv:.4f}\")\n",
        "    print(f\"F-Score: {f1:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "\n",
        "    # Confusion matrixの描画\n",
        "    # 混同行列の可視化\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # ROC曲線の描画\n",
        "    fpr, tpr, thresholds = roc_curve(actuals, probas)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.plot(fpr, tpr, color='blue', label='ROC curve (AUC = %0.2f)' % auc)\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "id": "G85DaLzX6IQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## CNNで画像分類\n",
        "* モデル名を`vit_base_patch16_224_in21k` → `tf_efficientnetv2_s_in21ft1k`\n",
        "* 重みファイル名を`/content/drive/MyDrive/bestViTmodel.pth` → `/content/drive/MyDrive/bestmodel_efficientnet.pth`\n",
        "\n",
        "に変更して、CNNにおける混同行列、ROC曲線、AUCを計算しなさい。\n"
      ],
      "metadata": {
        "id": "l0qC22tJ7oDy"
      }
    }
  ]
}